{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ddbdb2cd-4f0b-4f1e-80e4-0303d6638eba",
      "metadata": {
        "id": "ddbdb2cd-4f0b-4f1e-80e4-0303d6638eba"
      },
      "source": [
        "Develop a Recurrent Neural Network Text Classification Model in Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d77ccac4-5b1a-4050-ad1e-f50ea6d4911d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d77ccac4-5b1a-4050-ad1e-f50ea6d4911d",
        "outputId": "aaf20c86-c6bd-4aba-9ff1-4426e8302be1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Code Block 1\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e34ded3-47bb-4480-8022-d1e0bbc22376",
      "metadata": {
        "id": "1e34ded3-47bb-4480-8022-d1e0bbc22376"
      },
      "source": [
        "We will be utilizing the women's clothing customer review dataset found on Kaggle (https://www.kaggle.com/datasets/nicapotato/womens-ecommerce-clothing-reviews) to determine if, given a customer's review, we can predict if a customer would recommend the product or not. We are specifically interested in how well we can predict if a customer would **not** recommend a specific product (Recommended IND = 0), and will attempt to create a model with this aspect in mind.  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code Block 2\n",
        "!git clone https://github.com/tabishkhan72/nlp-customer-review-classification.git\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tx9xX48O1KW",
        "outputId": "156dae4f-c090-42b0-ab68-9f8a5b06a49b"
      },
      "id": "5Tx9xX48O1KW",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'nlp-customer-review-classification' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code Block 3\n",
        "import sys\n",
        "sys.path.insert(0,'/content/nlp-customer-review-classification')"
      ],
      "metadata": {
        "id": "k5UeNm18Qtxm"
      },
      "id": "k5UeNm18Qtxm",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "fec4f8e7-c7e1-493f-bb69-d2f06f9df32e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fec4f8e7-c7e1-493f-bb69-d2f06f9df32e",
        "outputId": "cc556567-63b6-474c-9cd0-78d24c41fa18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23486"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "#Code Block 4\n",
        "# import the clothing review dataset \n",
        "clothing_data = pd.read_csv(\n",
        "    \"/content/nlp-customer-review-classification/data/clothing_reviews.csv\", \n",
        "    usecols=['Review Text', 'Recommended IND', 'Rating'], \n",
        "    dtype={'Review Text': str, 'Recommended IND': np.int64, 'Rating': np.int64}\n",
        ")\n",
        "clothing_data.rename(columns={\"Review Text\": \"Text\"}, inplace=True)\n",
        "clothing_data.rename(columns={\"Recommended IND\": \"Would Recommend\"}, inplace=True)\n",
        "\n",
        "len(clothing_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "pyssYUNLKT8t"
      },
      "id": "pyssYUNLKT8t"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d564d3ea-fe4a-4a4d-8ec2-f4206543e4b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d564d3ea-fe4a-4a4d-8ec2-f4206543e4b9",
        "outputId": "cf2e9c9a-0816-4e36-ca59-3e40d8166331"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8223622583666865"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Code Block 5\n",
        "# calculate total ratio of 'Would Recommend' to 'Would Not Recommend'\n",
        "sum(clothing_data['Would Recommend'])/len(clothing_data['Would Recommend'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "94c1f76e-ac04-45b9-a5e3-b993cb5c2cff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "94c1f76e-ac04-45b9-a5e3-b993cb5c2cff",
        "outputId": "1ae45c28-1309-460b-cdb8-c2d825aa0c68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text  Rating  Would Recommend\n",
              "0  Absolutely wonderful - silky and sexy and comf...       4                1\n",
              "1  Love this dress!  it's sooo pretty.  i happene...       5                1\n",
              "2  I had such high hopes for this dress and reall...       3                0\n",
              "3  I love, love, love this jumpsuit. it's fun, fl...       5                1\n",
              "4  This shirt is very flattering to all due to th...       5                1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f42bbf5a-7906-4d4f-ab66-fc7f1a046ce9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Would Recommend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I had such high hopes for this dress and reall...</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>This shirt is very flattering to all due to th...</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f42bbf5a-7906-4d4f-ab66-fc7f1a046ce9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f42bbf5a-7906-4d4f-ab66-fc7f1a046ce9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f42bbf5a-7906-4d4f-ab66-fc7f1a046ce9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#Code Block 6\n",
        "# view a snapshow of what our data looks like\n",
        "clothing_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f4cee5e-118c-47ae-a396-a79f0bce70cc",
      "metadata": {
        "id": "9f4cee5e-118c-47ae-a396-a79f0bce70cc"
      },
      "source": [
        "We will first import the necessary variables (the review text & if the customer would recommend the piece or not), along with the rating, which we may be able to use as validation to see if another model may be more useful. We will then split the data into training, validation, and testing datasets, with 20% of the original data being used as test data and 20% of the training set being used as validation data. We can see from our import that there are a total of 23,486 reviews, with 82.23% of them resulting in a 'Would Recommend' rating (with 0 = Would Not Recommend, 1 = Would Recommend). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "06de60d2-9a92-4ee9-b0cc-c4c9110cc8b4",
      "metadata": {
        "id": "06de60d2-9a92-4ee9-b0cc-c4c9110cc8b4"
      },
      "outputs": [],
      "source": [
        "#Code Block 7\n",
        "x = clothing_data['Text']\n",
        "y = clothing_data['Would Recommend']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 123)  \n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state = 123) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "10ae4daa-e3b4-47d5-8a9d-435797232498",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10ae4daa-e3b4-47d5-8a9d-435797232498",
        "outputId": "0bbdd9ab-297d-4d5f-a768-cd3c032e163a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13230    Super easy and cute. i received lots of compli...\n",
              "4644     I really love this top. it looks great under a...\n",
              "5992     I purchased the teal/blue version and the colo...\n",
              "1791     I bought the grey and white plaid shirt in a l...\n",
              "13652    Beautiful detail. sweater is warm, soft, and v...\n",
              "Name: Text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "\n",
        "#Code Block 8\n",
        "x_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2b5955f7-5975-4e52-b084-8b380aab10a7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b5955f7-5975-4e52-b084-8b380aab10a7",
        "outputId": "a522f8c6-af4f-49d6-d8b1-5da9e122fa36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8216899534264803"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#Code Block 9\n",
        "sum(y_train)/len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "ae9df1c1-ec23-4f1f-80db-18b8d7c149f3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae9df1c1-ec23-4f1f-80db-18b8d7c149f3",
        "outputId": "b3a00b34-464f-40ab-94c6-eb312109b81d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.810803618946248"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "#Code Block 10\n",
        "sum(y_val)/len(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "074b4624-2542-411d-953a-1a0ebd19b524",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "074b4624-2542-411d-953a-1a0ebd19b524",
        "outputId": "b2728578-2d72-43f4-cf99-f1110b1a151e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8337590464027246"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#Code Block 11\n",
        "sum(y_test)/len(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "794c422e-2b2b-4d0a-b67e-a656990fe3a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "794c422e-2b2b-4d0a-b67e-a656990fe3a9",
        "outputId": "7c0b8719-feeb-4b6f-f7b0-861f1e17904a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text  Would Recommend\n",
              "0  Super easy and cute. i received lots of compli...                1\n",
              "1  I really love this top. it looks great under a...                1\n",
              "2  I purchased the teal/blue version and the colo...                1\n",
              "3  I bought the grey and white plaid shirt in a l...                1\n",
              "4  Beautiful detail. sweater is warm, soft, and v...                1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05249cf9-2e3f-4303-b3ee-df1a94468410\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Would Recommend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Super easy and cute. i received lots of compli...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I really love this top. it looks great under a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I purchased the teal/blue version and the colo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I bought the grey and white plaid shirt in a l...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Beautiful detail. sweater is warm, soft, and v...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05249cf9-2e3f-4303-b3ee-df1a94468410')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-05249cf9-2e3f-4303-b3ee-df1a94468410 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-05249cf9-2e3f-4303-b3ee-df1a94468410');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#Code Block 12\n",
        "train_data = np.column_stack((x_train, y_train))\n",
        "train_data = pd.DataFrame(train_data, columns = ['Text','Would Recommend'])\n",
        "\n",
        "# make sure to reset data to necessary type\n",
        "type_dict = {'Text': str,\n",
        "             'Would Recommend': np.int64\n",
        "                }\n",
        " \n",
        "train_data = train_data.astype(type_dict)\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "75a32b90-1840-4b40-8d26-f72546bb08f2",
      "metadata": {
        "id": "75a32b90-1840-4b40-8d26-f72546bb08f2"
      },
      "outputs": [],
      "source": [
        "#Code Block 13\n",
        "val_data = np.column_stack((x_val, y_val))\n",
        "val_data = pd.DataFrame(val_data, columns = ['Text','Would Recommend'])\n",
        "val_data = val_data.astype(type_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1966f1b0-68fd-4b83-a00c-f1e1d5a60b78",
      "metadata": {
        "id": "1966f1b0-68fd-4b83-a00c-f1e1d5a60b78"
      },
      "outputs": [],
      "source": [
        "#Code Block 14\n",
        "test_data = np.column_stack((x_test, y_test))\n",
        "test_data = pd.DataFrame(test_data, columns = ['Text','Would Recommend'])\n",
        "test_data = test_data.astype(type_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee7694c8-d4bc-4b7e-bccf-28e2e353f7de",
      "metadata": {
        "id": "ee7694c8-d4bc-4b7e-bccf-28e2e353f7de"
      },
      "source": [
        "We will next clean our text data, to remove any unwanted noise from things like urls or punctuation (done through TensorFlow tokenizer). We will also remove stop words like 'a' or 'the' that will not add meaning into our final model. Finally, we will revert the words in our data to their stem, or base derivation, which may help improve our model further. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ef68ebaa-9465-4f8b-b65c-319bb009d77e",
      "metadata": {
        "id": "ef68ebaa-9465-4f8b-b65c-319bb009d77e"
      },
      "outputs": [],
      "source": [
        "#Code Block 15\n",
        "\n",
        "# remove urls from text\n",
        "def remove_url(sentence):\n",
        "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
        "    return url.sub(r'', sentence)\n",
        "\n",
        "# remove any emojis from text\n",
        "def remove_emoji(sentence):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    \n",
        "    return emoji_pattern.sub(r'', sentence)\n",
        "\n",
        "# remove stopwords\n",
        "def remove_stopwords(sentence):\n",
        "    words = sentence.split()\n",
        "    words = [word for word in words if word not in stopwords.words('english')]\n",
        "    \n",
        "    return ' '.join(words)\n",
        "\n",
        "# \n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "def stem_words(sentence):\n",
        "    words = sentence.split()\n",
        "    words = [stemmer.stem(word) for word in words ]\n",
        "    \n",
        "    return ' '.join(words)\n",
        "\n",
        "def clean_text(data):\n",
        "    data['Text'] = data['Text'].apply(lambda x : remove_url(x))\n",
        "    data['Text'] = data['Text'].apply(lambda x : remove_emoji(x))\n",
        "    data['Text'] = data['Text'].apply(lambda x : remove_stopwords(x))\n",
        "    data['Text'] = data['Text'].apply(lambda x : stem_words(x))\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "5e5debf1-72c1-43cc-8f59-e035fda00faf",
      "metadata": {
        "id": "5e5debf1-72c1-43cc-8f59-e035fda00faf"
      },
      "outputs": [],
      "source": [
        "#Code Block 16\n",
        "# clean the text of our training, validation, and testing data\n",
        "train_data = clean_text(train_data)\n",
        "val_data = clean_text(val_data)\n",
        "test_data = clean_text(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf91c60e-66f4-4a7a-80fa-bc47b4ec1ad2",
      "metadata": {
        "id": "cf91c60e-66f4-4a7a-80fa-bc47b4ec1ad2"
      },
      "source": [
        "After cleaning our data, we will now tokenize each of the text values so that our model can understand our input properly. To do this, we will utilise two functions that will assign index numbers to each word in the dataset, then encode the sentences so that each word is represented with an indexnumber in an array of index numbers, respectively. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "bc4fbc0c-f9ff-438d-a76f-c2e6c027bf4b",
      "metadata": {
        "id": "bc4fbc0c-f9ff-438d-a76f-c2e6c027bf4b"
      },
      "outputs": [],
      "source": [
        "#Code Block 17\n",
        "# function used to assign index numbers to each word\n",
        "def define_tokenizer(train_sentences, val_sentences, test_sentences):\n",
        "    sentences = pd.concat([train_sentences, test_sentences])\n",
        "    \n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    \n",
        "    return tokenizer\n",
        "\n",
        "# function used to encode each review into an array of index numbers\n",
        "def encode(sentences, tokenizer):\n",
        "    encoded_sentences = tokenizer.texts_to_sequences(sentences)\n",
        "    encoded_sentences = tf.keras.preprocessing.sequence.pad_sequences(encoded_sentences)\n",
        "    \n",
        "    return encoded_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ea344d3b-420e-46c6-a1dd-b3fed6a36c38",
      "metadata": {
        "id": "ea344d3b-420e-46c6-a1dd-b3fed6a36c38"
      },
      "outputs": [],
      "source": [
        "#Code Block 18\n",
        "# define and encode our text data\n",
        "tokenizer = define_tokenizer(train_data['Text'], val_data['Text'], test_data['Text'])\n",
        "\n",
        "encoded_train_reviews = encode(train_data['Text'], tokenizer)\n",
        "encoded_val_reviews = encode(val_data['Text'], tokenizer)\n",
        "encoded_test_reviews = encode(test_data['Text'], tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "0e512982-7554-4ffb-a0ea-c0ed1a715414",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e512982-7554-4ffb-a0ea-c0ed1a715414",
        "outputId": "cf421439-114c-4213-c8a3-f35837482930"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12318"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "#Code Block 19\n",
        "# number of words in encoding dictionary\n",
        "len(tokenizer.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a1d6762f-475d-415d-b2f6-6bd9519d1a0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1d6762f-475d-415d-b2f6-6bd9519d1a0c",
        "outputId": "e654b841-15ee-4617-a608-86590e6fa6b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lower:  True\n",
            "Split:   \n",
            "Filters:  !\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Code Block 20\n",
        "\n",
        "# view general information from tokenizer \n",
        "print('Lower: ', tokenizer.get_config()['lower'])\n",
        "print('Split: ', tokenizer.get_config()['split'])\n",
        "print('Filters: ', tokenizer.get_config()['filters'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b4e644e-f421-498b-ad4b-44efd0089067",
      "metadata": {
        "id": "4b4e644e-f421-498b-ad4b-44efd0089067"
      },
      "source": [
        "To make sure our model trains on a more complete array dataset, we will import the GloVe Embedding and synchronize this embedding with our own encoding in order to have a more complete dataset for our model to train on. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Code Block 21\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWvGbnCTM8Mu",
        "outputId": "2272670c-f896-47b0-ccb0-10d45ed7718b"
      },
      "id": "JWvGbnCTM8Mu",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "06f0d11e-428a-49d7-935a-7e60362316c5",
      "metadata": {
        "id": "06f0d11e-428a-49d7-935a-7e60362316c5"
      },
      "outputs": [],
      "source": [
        "#Code Block 22\n",
        "\n",
        "embedding_dict = {}\n",
        "\n",
        "with open(\"/content/drive/MyDrive/DATASET/glove.6B.100d.txt\",'r', encoding=\"utf8\") as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vectors = np.asarray(values[1:],'float32')\n",
        "        embedding_dict[word] = vectors\n",
        "        \n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "ad2b1886-a751-4d22-bf61-29f361137138",
      "metadata": {
        "id": "ad2b1886-a751-4d22-bf61-29f361137138"
      },
      "outputs": [],
      "source": [
        "#Code Block 23\n",
        "\n",
        "num_words = len(tokenizer.word_index) + 1\n",
        "embedding_matrix = np.zeros((num_words, 100))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if i > num_words:\n",
        "        continue\n",
        "    \n",
        "    emb_vec = embedding_dict.get(word)\n",
        "    \n",
        "    if emb_vec is not None:\n",
        "        embedding_matrix[i] = emb_vec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06f79dc1-399a-4af8-803e-05da89d5eaf5",
      "metadata": {
        "id": "06f79dc1-399a-4af8-803e-05da89d5eaf5"
      },
      "source": [
        "We will now make sure to convert our text data into the native TensorFlow data format, so that we can maximize TensorFlow functionality. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "c726c402-6cb1-4d47-9e5d-243d21d84555",
      "metadata": {
        "id": "c726c402-6cb1-4d47-9e5d-243d21d84555"
      },
      "outputs": [],
      "source": [
        "#Code Block 24\n",
        "\n",
        "# convert training data into native TensorFlow format\n",
        "tf_data = tf.data.Dataset.from_tensor_slices((encoded_train_reviews, train_data['Would Recommend'].values))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fcdafea-f184-4507-97c9-1c2f76e6e4b6",
      "metadata": {
        "id": "5fcdafea-f184-4507-97c9-1c2f76e6e4b6"
      },
      "source": [
        "We will now define the pipeline for our reformatted training data, along with reformatting and defining a pipeline for our validation data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a7139cea-0a0b-4b77-a5a2-86a8f401cdf4",
      "metadata": {
        "id": "a7139cea-0a0b-4b77-a5a2-86a8f401cdf4"
      },
      "outputs": [],
      "source": [
        "#Code Block 25\n",
        "\n",
        "# define pipeline\n",
        "def pipeline(tf_data, buffer_size=100, batch_size=32):\n",
        "    tf_data = tf_data.shuffle(buffer_size)    \n",
        "    tf_data = tf_data.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    tf_data = tf_data.padded_batch(batch_size, padded_shapes=([None],[]))\n",
        "    \n",
        "    return tf_data\n",
        "\n",
        "tf_data = pipeline(tf_data, buffer_size=1000, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "aaf978b5-cc68-4c13-aab9-70bca00f44a9",
      "metadata": {
        "id": "aaf978b5-cc68-4c13-aab9-70bca00f44a9"
      },
      "outputs": [],
      "source": [
        "#Code Block 26\n",
        "\n",
        "# convert validation data to native TensorFlow format\n",
        "tf_val_data = tf.data.Dataset.from_tensor_slices((encoded_val_reviews, val_data['Would Recommend'].values))\n",
        "\n",
        "# define pipeline\n",
        "def val_pipeline(tf_data, batch_size=1):        \n",
        "    tf_data = tf_data.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    tf_data = tf_data.padded_batch(batch_size, padded_shapes=([None],[]))\n",
        "    \n",
        "    return tf_data\n",
        "\n",
        "tf_val_data = val_pipeline(tf_val_data, batch_size=len(val_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d66bbe45-848b-42a8-9472-afbe36d39c86",
      "metadata": {
        "id": "d66bbe45-848b-42a8-9472-afbe36d39c86"
      },
      "source": [
        "After reformatting our data, we can now define our model. In this case, we will first define an embedding layer so that our model can gain an understanding of a words meaning, then an RNN layer so that our model can begin to build relationships between words. Finally, we will use our Dense layer to output if our text indicates a recommendation or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "25597fdb-5b99-49b0-a6c0-1441eb672a44",
      "metadata": {
        "id": "25597fdb-5b99-49b0-a6c0-1441eb672a44"
      },
      "outputs": [],
      "source": [
        "#Code Block 27\n",
        "\n",
        "# define the embedding, RNN & Dense layers of the model, using LSTM as our RNN model of choice in this instance\n",
        "\n",
        "embedding = tf.keras.layers.Embedding(\n",
        "    len(tokenizer.word_index) + 1,\n",
        "    100,\n",
        "    embeddings_initializer = tf.keras.initializers.Constant(embedding_matrix),\n",
        "    trainable = True\n",
        ")\n",
        "model = tf.keras.Sequential([\n",
        "    embedding,\n",
        "    tf.keras.layers.SpatialDropout1D(0.2),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2)),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "be4dd10e-73cc-4925-b7a4-f032a32c3490",
      "metadata": {
        "id": "be4dd10e-73cc-4925-b7a4-f032a32c3490"
      },
      "outputs": [],
      "source": [
        "#Code Block 28\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(0.0001),\n",
        "    metrics=['accuracy', 'Precision', 'Recall']\n",
        ")\n",
        "\n",
        "# make sure to avoid stepping past optimum\n",
        "callbacks = [\n",
        "    tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=2, verbose=1),\n",
        "    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=4, verbose=1),\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0097b5b1-f872-4108-ba69-2903a2a2c826",
      "metadata": {
        "id": "0097b5b1-f872-4108-ba69-2903a2a2c826"
      },
      "source": [
        "After defining and compiling our model, we will now fit our model over 10 epochs on our training dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "a1a8064a-32d0-48da-b1c0-20807f2336cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1a8064a-32d0-48da-b1c0-20807f2336cb",
        "outputId": "4c331f47-5640-47b8-fd78-4c54ad8feeb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "470/470 [==============================] - 464s 959ms/step - loss: 0.4624 - accuracy: 0.8159 - precision: 0.8222 - recall: 0.9901 - val_loss: 0.4356 - val_accuracy: 0.8127 - val_precision: 0.8132 - val_recall: 0.9984 - lr: 1.0000e-04\n",
            "Epoch 2/10\n",
            "470/470 [==============================] - 214s 455ms/step - loss: 0.3891 - accuracy: 0.8317 - precision: 0.8381 - recall: 0.9856 - val_loss: 0.4217 - val_accuracy: 0.8249 - val_precision: 0.8281 - val_recall: 0.9895 - lr: 1.0000e-04\n",
            "Epoch 3/10\n",
            "470/470 [==============================] - 229s 487ms/step - loss: 0.3602 - accuracy: 0.8424 - precision: 0.8578 - recall: 0.9689 - val_loss: 0.3611 - val_accuracy: 0.8433 - val_precision: 0.8497 - val_recall: 0.9800 - lr: 1.0000e-04\n",
            "Epoch 4/10\n",
            "470/470 [==============================] - 230s 490ms/step - loss: 0.3350 - accuracy: 0.8554 - precision: 0.8749 - recall: 0.9614 - val_loss: 0.3293 - val_accuracy: 0.8598 - val_precision: 0.8757 - val_recall: 0.9639 - lr: 1.0000e-04\n",
            "Epoch 5/10\n",
            "470/470 [==============================] - 263s 560ms/step - loss: 0.3165 - accuracy: 0.8636 - precision: 0.8877 - recall: 0.9547 - val_loss: 0.3161 - val_accuracy: 0.8675 - val_precision: 0.8852 - val_recall: 0.9613 - lr: 1.0000e-04\n",
            "Epoch 6/10\n",
            "470/470 [==============================] - 223s 475ms/step - loss: 0.3028 - accuracy: 0.8713 - precision: 0.8938 - recall: 0.9571 - val_loss: 0.3209 - val_accuracy: 0.8683 - val_precision: 0.8823 - val_recall: 0.9665 - lr: 1.0000e-04\n",
            "Epoch 7/10\n",
            "470/470 [==============================] - 211s 450ms/step - loss: 0.2918 - accuracy: 0.8766 - precision: 0.9022 - recall: 0.9531 - val_loss: 0.2982 - val_accuracy: 0.8733 - val_precision: 0.8899 - val_recall: 0.9629 - lr: 1.0000e-04\n",
            "Epoch 8/10\n",
            "470/470 [==============================] - 221s 470ms/step - loss: 0.2780 - accuracy: 0.8809 - precision: 0.9063 - recall: 0.9536 - val_loss: 0.2963 - val_accuracy: 0.8760 - val_precision: 0.8943 - val_recall: 0.9606 - lr: 1.0000e-04\n",
            "Epoch 9/10\n",
            "470/470 [==============================] - 209s 444ms/step - loss: 0.2681 - accuracy: 0.8869 - precision: 0.9113 - recall: 0.9554 - val_loss: 0.3159 - val_accuracy: 0.8747 - val_precision: 0.8829 - val_recall: 0.9747 - lr: 1.0000e-04\n",
            "Epoch 10/10\n",
            "470/470 [==============================] - 221s 470ms/step - loss: 0.2623 - accuracy: 0.8876 - precision: 0.9132 - recall: 0.9538 - val_loss: 0.3002 - val_accuracy: 0.8792 - val_precision: 0.8906 - val_recall: 0.9701 - lr: 1.0000e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff67102aee0>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "#Code Block 29\n",
        "\n",
        "model.fit(\n",
        "    tf_data, \n",
        "    validation_data = tf_val_data,\n",
        "    epochs = 10,\n",
        "    callbacks = callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd38f8cf-6d46-447e-a6c8-9dc1e4406f0f",
      "metadata": {
        "id": "bd38f8cf-6d46-447e-a6c8-9dc1e4406f0f"
      },
      "source": [
        "To evaluate our model, we will use the model F1 score on our validation data, to check that our model is perfoming adequately before testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "b63b1c61-939a-4611-943b-0d1c72ffca65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b63b1c61-939a-4611-943b-0d1c72ffca65",
        "outputId": "d0444540-a82c-4578-ff52-3f046a9b5130"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step - loss: 0.3002 - accuracy: 0.8792 - precision: 0.8906 - recall: 0.9701\n",
            "F1 score: 0.928683631301736\n"
          ]
        }
      ],
      "source": [
        "#Code Block 30\n",
        "metrics = model.evaluate(tf_val_data)\n",
        "\n",
        "precision = metrics[2]\n",
        "recall = metrics[3]\n",
        "f1 = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "print('F1 score: ' + str(f1)) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbf09568-06c8-464a-8a72-f6090d9c7c97",
      "metadata": {
        "id": "cbf09568-06c8-464a-8a72-f6090d9c7c97"
      },
      "source": [
        "From our F1 score of 0.927, we can be fairly confident that our model will perform well with our test data. We will now create a new pipeline definition for our test data, then use our model to predict if the review implies a potential recommendation or not. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "b15a4402-4a9a-4691-bfab-c08e53fdd1f8",
      "metadata": {
        "id": "b15a4402-4a9a-4691-bfab-c08e53fdd1f8"
      },
      "outputs": [],
      "source": [
        "#Code Block 31\n",
        "tf_test_data = tf.data.Dataset.from_tensor_slices((encoded_test_reviews))\n",
        "\n",
        "def test_pipeline(tf_data, batch_size=1):        \n",
        "    tf_data = tf_data.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    tf_data = tf_data.padded_batch(batch_size, padded_shapes=([None]))\n",
        "    \n",
        "    return tf_data\n",
        "\n",
        "tf_test_data = test_pipeline(tf_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "fd56d1a6-57b4-4734-b1b2-a6b50946b305",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd56d1a6-57b4-4734-b1b2-a6b50946b305",
        "outputId": "3af4ae47-7ff1-4a99-d43f-f3b9aebdd5a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4698/4698 [==============================] - 143s 30ms/step\n"
          ]
        }
      ],
      "source": [
        "#Code Block 32\n",
        "predictions = model.predict(tf_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "19cb3483-90ae-411e-a82a-b90b975f8405",
      "metadata": {
        "id": "19cb3483-90ae-411e-a82a-b90b975f8405"
      },
      "outputs": [],
      "source": [
        "#Code Block 33\n",
        "predictions = np.concatenate(predictions).round().astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "5774391e-ff92-45a7-a086-689ae3914263",
      "metadata": {
        "id": "5774391e-ff92-45a7-a086-689ae3914263"
      },
      "outputs": [],
      "source": [
        "#Code Block 34\n",
        "compare = np.column_stack((y_test, predictions))\n",
        "compare = pd.DataFrame(compare, columns = ['Test Recommendation','Predicted Recommendation'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "c5bd4c8e-9e94-4c96-83d3-5504558816b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c5bd4c8e-9e94-4c96-83d3-5504558816b9",
        "outputId": "855beecb-a4d5-4923-a2c7-96578f91a34f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8888888888888888"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "#Code Block 35\n",
        "# determine percentage of correct predictions\n",
        "len(compare.query('`Test Recommendation` == `Predicted Recommendation`'))/len(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "c559b8ea-fa92-4379-b3e4-6aa56a351dbe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c559b8ea-fa92-4379-b3e4-6aa56a351dbe",
        "outputId": "c5fe670e-9b2a-449c-8cda-76a4a285d4f8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7701149425287356"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "#Code Block 36\n",
        "# determine ratio of false positives to total incorrect predictions\n",
        "incorrect_prediction = compare.query('`Test Recommendation` != `Predicted Recommendation`')\n",
        "false_recommendation = incorrect_prediction.query('`Test Recommendation` == 0')   \n",
        "len(false_recommendation)/len(incorrect_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2aab6e8-feae-45d2-aa79-52e34f049822",
      "metadata": {
        "id": "a2aab6e8-feae-45d2-aa79-52e34f049822"
      },
      "source": [
        "From our predictions, we can see that we have correctly predicted about 88.25% of the total number of test reviews, which in most cases is extremely high and shows a useful model. However, we can see that of our incorrect predictions, about 74.67% of them are of incorrectly predicting that a customer would recommend a piece of clothing when they would not. This means that, while we have an overall fairly accurate model, a lot of our accuracy comes from the dramatic skew in our data towards positive recommendations. Therefore, while our model does predict better than average ( ~ 80% from guessing with respects to the predetermined ratios), we can still see potential improvements in this model. One such potential improvement is to determine a way to adequately weigh the negative reviews higher, without creating unwanted bias or adding negative sentiment to words that may not necessarly call for it. "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}